{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "---\n",
    "\n",
    "Released on Nov 26 -- due by *Dec 3, 11:59pm*.\n",
    "\n",
    "In this homework assignment we will develop a copy number caller based on a Hidden Markov Model. In addition, we will implement a hierarchical clustering algorithm. The data that we consider is from a previously published [breast tumor](http://dx.doi.org/10.1038/nature09807), from which 100 single cells have been sequenced. In this homework assignment we restrict our attention to a subset of 25 cells.\n",
    "\n",
    "_Instructions:_ There are four questions, worth a total of 100 points. In addition, there are two bonus questions (Q2e and Q4c), each worth 5 points. Insert your answer after each question in the designated box. Replace comments with code.\n",
    "\n",
    "Hand in your work by emailing the Jupyter notebook (please rename as \"LASTNAME_FIRSTNAME.ipynb\") to Anusri and myself.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Data preparation [20 points]\n",
    "\n",
    "We start by parsing the data from `data.tsv` using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.tsv\", sep=\"\\t\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of the following 25 cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = list(df.columns[3:])\n",
    "sys.stdout.write(\"Cells:\")\n",
    "for idx, cell in enumerate(cells):\n",
    "    if idx % 5 == 0:\n",
    "        sys.stdout.write(\"\\n\")\n",
    "    sys.stdout.write(cell + \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reads of each cell are put in bins. As seen in the command below, there are 5363 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot a histogram of the bin sizes as follows, from which we can see that most of the bins have length 500,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['END'] - df['START'] + 1).hist(bins=1000, xrot=90)\n",
    "plt.xlim((400000, 1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q1a:_ What is the minimum, median and maximum bin size? [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: insert code to print the min, median and max bin size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_ \n",
    "* min: XXX\n",
    "* median: XXX\n",
    "* max: XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retain bins with lengths between 450,000 and 500,000 using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(450000 <= (df['END'] - df['START'] + 1)) & ((df['END'] - df['START'] + 1) <= 550000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q1b:_ The column `CHR` contains the chromosome label. Do these cells originate from a male or female patient? [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write code here to print unique list of values in 'CHR' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_ male/female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we remove the sex chromosomes such that each bin in a normal cell has copy number 2.\n",
    "### _Q1c:_ How many bins occur on autosomal chromosomes? [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: insert code to generate a list of chromosome labels corresponding to autosomes, e.g. ['chr1', 'chr2', ...]\n",
    "autosomes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['CHR'].isin(autosomes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_ XXX bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we retain only autosomes\n",
    "df = df[df['CHR'].isin(autosomes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to variablity in library preparation, there are differences in the total number of reads per cell. We construct a new dataframe with the total number of reads, and plot a histogram as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_reads = pd.DataFrame.from_records([(cell, int(df[cell].sum())) for cell in cells], columns=['cell', 'total'])\n",
    "df_total_reads.hist(column=\"total\", bins=15, xrot=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q1d:_ Based on the above plot, we decide to exclude the six cells with a total read count of less than 3,000,000 reads. Which six cells are excluded? [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_to_keep = list(df_total_reads[df_total_reads['total'] >= 3000000]['cell'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: insert code to filter down to cells with less 3,000,000 reads\n",
    "df_removed_cells = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_ \n",
    "1. XXX with YYY reads; \n",
    "2. XXX with YYY reads; \n",
    "3. XXX with YYY reads; \n",
    "4. XXX with YYY reads; \n",
    "5. XXX with YYY reads;\n",
    "6. XXX with YYY reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we retain only cells with >= 300,000 reads\n",
    "df = df[list(df.columns)[:3] + cells_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key concept is that the majority of bins in a cell are diploid. Since the bins have the same length and under the assumption of uniform genome coverage, we expect the most frequent read count, or the mode, to correspond to the diploid state. We identify the mode by discretizing the read counts for each cell into 20 bins. We then divide the read count for each bin in a cell by the mode.\n",
    "\n",
    "### _Q1e:_ Complete the below code fragment to identify the mode of each cell and to subsequently normalize the read counts. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_bins = 20\n",
    "df2 = df.copy(deep=True)\n",
    "for cell in cells_to_keep:\n",
    "    # insert code to discretize read count (e.g. first integer division by bin_size, then multiply by bin_size)\n",
    "    largest = None\n",
    "    bin_size = None\n",
    "    df2[cell] = None\n",
    "    \n",
    "df_mode = pd.DataFrame.from_records([(cell, int(df2[cell].mode())) for cell in cells_to_keep], \n",
    "                                    columns=['cell', 'mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: insert code to divide each read count by the mode of the corresponding cell\n",
    "for cell in cells_to_keep:\n",
    "    df[cell] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following commented out code generates data_filtered.tsv, which is part of the zip file of this assignment. \n",
    "# If your code is correct the resulting file should be identical to the provided file.\n",
    "# df.to_csv(\"data_filtered_normalized.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Viterbi algorithm [50 points]\n",
    "\n",
    "In this question we use the Viterbi algorithm to compute a copy number for each bin. The set $Q$ of hidden states corresponds to integer copy numbers. We consider $Q=\\{0,\\ldots,10\\}$. The set $\\Sigma$ of emitted symbols are normalized read counts. Since this an infinite set, we use a probability distribution function for each integer copy number to define the emission probabilities. Specifically, for copy number $c \\in \\{0,\\ldots,10\\}$ we use a normal distribution with standard deviation $\\sigma = 0.1$ centered around mean $\\mu_c = c / 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.read_table(\"data_filtered_normalized.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x, mu, sigma, A):\n",
    "    return A*np.exp(-(x-mu)**2/2/sigma**2)\n",
    "\n",
    "values = [val for sublist in [list(df_norm[cell]) for cell in list(df_norm.columns[3:])] for val in sublist]\n",
    "count, bins, ignored = plt.hist(values, 100, density=True)\n",
    "\n",
    "sigma = 0.1\n",
    "\n",
    "plt.plot(np.array([0,.05,.1,.15,.2]),gauss(np.array([0,.05,.1,.15,.2]), 0, sigma, .01),color='black',lw=3,label='copy number 0')\n",
    "plt.plot(bins,gauss(bins, 0.5, sigma, .25),color='red',lw=3,label='copy number 1')\n",
    "plt.plot(bins,gauss(bins, 1, sigma, 1.3),color='blue',lw=3,label='copy number 2')\n",
    "plt.plot(bins,gauss(bins, 1.5, sigma, .7),color='cyan',lw=3,label='copy number 3')\n",
    "plt.plot(bins,gauss(bins, 2, sigma, .25),color='orange',lw=3,label='copy number 4')\n",
    "plt.plot(bins,gauss(bins, 2.5, sigma, .1),color='purple',lw=3,label='copy number 5')\n",
    "plt.plot(bins,gauss(bins, 3, sigma, .05),color='pink',lw=3,label='copy number 6')\n",
    "plt.plot(bins,gauss(bins, 3.5, sigma, .05),color='gray',lw=3,label='copy number 7')\n",
    "plt.plot(bins,gauss(bins, 4, sigma, .05),color='yellow',lw=3,label='copy number 8')\n",
    "plt.plot(bins,gauss(bins, 4.5, sigma, .05),color='pink',lw=3,label='copy number 9')\n",
    "plt.plot(bins,gauss(bins, 5, sigma, .05),color='black',lw=3,label='copy number 10')\n",
    "\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches(10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "max_copy_number = 10\n",
    "\n",
    "def emissionLogProb(copy_number, norm_count):\n",
    "    sigma = 0.1\n",
    "    mu = copy_number / 2.\n",
    "\n",
    "    # Compute Pr(|X_c - norm_count| <= 0.01 | c)  \n",
    "    low = norm.cdf(norm_count - 0.01, mu, sigma)\n",
    "    up = norm.cdf(norm_count + 0.01, mu, sigma)\n",
    "    \n",
    "    # prevent probability of 0\n",
    "    prob = max(up - low, 0.0001)\n",
    "    \n",
    "    return np.log(prob)\n",
    "\n",
    "def transitionLogProb(current_copy_number, next_copy_number):\n",
    "    stay_prob = 0.99999\n",
    "    if current_copy_number == next_copy_number:\n",
    "        return np.log(stay_prob)\n",
    "    elif 0 <= next_copy_number <= max_copy_number:\n",
    "        return np.log((1 - stay_prob) / max_copy_number)\n",
    "    else:\n",
    "        return np.log(0)\n",
    "\n",
    "def initialLogProb(copy_number):\n",
    "    if 0 <= copy_number <= max_copy_number:\n",
    "        return np.log(1./11)\n",
    "    else:\n",
    "        return np.log(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q2a:_ Compute the joint log probability of each cell having copy number 2 in all bins. [10 points]\n",
    "\n",
    "_Hint:_ Make use of the functions `emissionLogProb`, `initialLogProb` and `transitionLogProb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in list(df_norm.columns[3:]):\n",
    "    log_prob = 0\n",
    "    for idx, norm_count in df_norm[cell].iteritems():\n",
    "        # TODO: insert code here\n",
    "        # Hint: idx == 0 is the initial item.\n",
    "        pass\n",
    "    \n",
    "    print(cell, log_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q2b:_ Determine the maximum joint log probability of each cell using the Viterbi algorithm. [20 points]\n",
    "\n",
    "_Hint:_ Complete the function `viterbi` and `max_joint_prob`, making use of the functions `emissionLogProb`, `initialLogProb` and `transitionLogProb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(df_norm, cell):\n",
    "    # Positions\n",
    "    bins = sorted(list(df_norm.index))\n",
    "\n",
    "    # Set of states (copy numbers)\n",
    "    Q = range(max_copy_number+1)\n",
    "    \n",
    "    # Initialization v[copy_number][bin] = 0\n",
    "    v = [ { bin : 0 for bin in bins } for c in range(max_copy_number + 1) ]\n",
    "    \n",
    "    for idx, bin in enumerate(bins):\n",
    "        norm_count = float(df.loc[bin][cell])\n",
    "        \n",
    "        # TODO: insert code here\n",
    "        pass\n",
    "\n",
    "    return v\n",
    "\n",
    "def max_joint_prob(df_norm, v):\n",
    "    # Positions\n",
    "    bins = sorted(list(df_norm.index))\n",
    "    \n",
    "    # Set of states (copy numbers)\n",
    "    Q = range(max_copy_number+1)\n",
    "    last_bin = bins[-1]\n",
    "    \n",
    "    # TODO: insert code here\n",
    "    return None\n",
    "\n",
    "V = {}\n",
    "for cell in list(df_norm.columns[3:]):\n",
    "    V[cell] = viterbi(df_norm, cell)\n",
    "    print(cell, \"--\", \"max prob:\", max_joint_prob(df_norm, V[cell]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q2c:_ Compute the most likely copy number profile for each cell. [10 points]\n",
    "\n",
    "_Hint:_ Hint perform a backtrace or extend the above `viterbi` function to maintain backpointers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_bt(df_norm, cell):\n",
    "    # Positions\n",
    "    bins = sorted(list(df_norm.index))\n",
    "\n",
    "    # Set of states (copy numbers)\n",
    "    Q = range(max_copy_number+1)\n",
    "    \n",
    "    # Initialization v[copy_number][bin] = 0\n",
    "    v = [ { bin : 0 for bin in bins } for c in range(max_copy_number + 1) ]\n",
    "    bt = [ { bin : None for bin in bins } for c in range(max_copy_number + 1) ]\n",
    "    \n",
    "    for idx, bin in enumerate(bins):\n",
    "        # TODO: insert code here\n",
    "        pass\n",
    "\n",
    "    return v, bt\n",
    "\n",
    "bins = sorted(list(df_norm.index))\n",
    "Q = range(max_copy_number+1)\n",
    "\n",
    "V = {}\n",
    "BT = {}\n",
    "C = {}\n",
    "for cell in list(df_norm.columns[3:]):\n",
    "    V[cell], BT[cell] = viterbi_bt(df_norm, cell)\n",
    "    C[cell] = {}\n",
    "    \n",
    "    max_prob = max_joint_prob(df_norm, V[cell])\n",
    "    final_c = None\n",
    "    final_bin = bins[-1]\n",
    "    for c in Q:\n",
    "        if V[cell][c][final_bin] == max_prob:\n",
    "            final_c = c\n",
    "    \n",
    "    C[cell][final_bin] = final_c\n",
    "    \n",
    "    for idx in range(len(bins)-2, -1, -1):\n",
    "        bin = bins[idx]\n",
    "        next_bin = bins[idx + 1]\n",
    "        next_bin_c = C[cell][next_bin]\n",
    "        C[cell][bin] = BT[cell][next_bin_c][next_bin]\n",
    "    \n",
    "    print(cell, \"--\", \"max prob:\", max_joint_prob(df_norm, V[cell]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q2d:_ Which cells are normal cells (i.e. have copy number 2 for each bin)? [10 points]\n",
    "\n",
    "_Hint:_ Use `visualizeCopyNumbers(C, bins)`.\n",
    "\n",
    "_Answer:_ XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = sorted(list(df_norm.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeCopyNumbers(C, bins):\n",
    "    nrRows = 5\n",
    "    nrCols = 4\n",
    "    for idx, cell in enumerate(C):\n",
    "        ax = plt.subplot(nrRows, nrCols, idx+1)\n",
    "        plt.step(range(len(bins)), C[cell].values())\n",
    "        ax.set_title(cell)\n",
    "        ax.set_ylim((0, 10))\n",
    "        ax.set_xlabel(\"bin\")\n",
    "        ax.set_ylabel(\"copy number\")\n",
    "    plt.gcf().set_size_inches(30, 20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"viterbi.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeCopyNumbers(C, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q2e -- Bonus:_ Extend the plotting function to delineate chromosomes using vertical lines. Do not forget to update x-axis labels to show chromosomes. [5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Forward algorithm [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q3a:_ Compute the marginal log probability of the observations using the forward algorithm. [10 points]\n",
    "_Hint:_ Be aware that recurrence of the forward algorithm includes a summation, but we are operating in log space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(df_norm, cell):\n",
    "    # Positions\n",
    "    bins = sorted(list(df_norm.index))\n",
    "\n",
    "    # Set of states (copy numbers)\n",
    "    Q = range(max_copy_number+1)\n",
    "    \n",
    "    # Initialization f[copy_number][bin] = 0\n",
    "    f = [ { bin : 0 for bin in bins } for c in range(max_copy_number + 1) ]\n",
    "    \n",
    "    for idx, bin in enumerate(bins):\n",
    "        norm_count = float(df.loc[bin][cell])\n",
    "        \n",
    "        # TODO: insert code here\n",
    "        pass\n",
    "\n",
    "    return f\n",
    "\n",
    "def marginal_log_prob(df_norm, f):\n",
    "    # Positions\n",
    "    bins = sorted(list(df_norm.index))\n",
    "    \n",
    "    # Set of states (copy numbers)\n",
    "    Q = range(max_copy_number+1)\n",
    "    last_bin = bins[-1]\n",
    "    \n",
    "    # insert code here\n",
    "    return None\n",
    "\n",
    "F = {}\n",
    "for cell in list(df_norm.columns[3:]):\n",
    "    F[cell] = forward(df_norm, cell)\n",
    "    print(cell, \"--\", \"marginal log prob:\", marginal_log_prob(df_norm, F[cell]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Hierarchical clustering [20 points]\n",
    "The Python package `scipy` implements hierarchical clustering. We will use this method to perform single linkage cluster with the Manhattan (also known as cityblock) distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [C[cell].values() for cell in C]\n",
    "C_labels = C.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "Z = hierarchy.linkage(C_values, 'single', 'cityblock')\n",
    "plt.figure()\n",
    "dn = hierarchy.dendrogram(Z, labels=C_labels, leaf_rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this question is to reimplement this algorithm. We start by computing the initial distance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q4a:_ Compute the initial distance matrix using Manhattan distance. [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan(C, cell_1, cell_2, bins):\n",
    "    # TODO: insert code here\n",
    "    return None\n",
    "\n",
    "bins = sorted(list(df_norm.index))\n",
    "dist = {}\n",
    "for cell_1 in C.keys():\n",
    "    dist[cell_1] = {}\n",
    "    for cell_2 in C.keys():\n",
    "        dist[cell_1][cell_2] = manhattan(C, cell_1, cell_2, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q4b:_ Implement single linkage clustering. [10 points]\n",
    "_Hint:_ The documentation for the required output format is described here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def cluster(distances):\n",
    "    distances = copy.deepcopy(distances)\n",
    "    clusters = set(distances.keys())\n",
    "    n = len(clusters)\n",
    "    cluster2idx = { cell : idx for idx, cell in enumerate(clusters) }\n",
    "    idx2cluster = distances.keys()\n",
    "    Z = np.empty((0, 4), float)\n",
    "    membership = [ set([cluster2idx[cell]]) for cell in clusters ]\n",
    "    while len(clusters) > 1:\n",
    "        # TODO: insert code to identify pair (c1, c2) with minimum distance dist\n",
    "        dist, c1, c2 = None, None, None\n",
    "\n",
    "        idx_c1 = cluster2idx[c1]\n",
    "        idx_c2 = cluster2idx[c2]\n",
    "        new_cluster = n + len(Z)\n",
    "        new_cluster_idx = len(idx2cluster)\n",
    "\n",
    "        membership.append( membership[idx_c1] | membership[idx_c2])\n",
    "        Z = np.append(Z, \n",
    "                      np.array([[cluster2idx[c1], cluster2idx[c2], dist, len(membership[new_cluster_idx])]]), \n",
    "                      axis=0)\n",
    "        \n",
    "        # TODO: insert code to update distances\n",
    "        distances[new_cluster] = {}\n",
    "\n",
    "\n",
    "        clusters.add(new_cluster)\n",
    "        cluster2idx[new_cluster] = len(idx2cluster)\n",
    "        idx2cluster.append(new_cluster)\n",
    "\n",
    "        clusters.remove(c1)\n",
    "        clusters.remove(c2)\n",
    "        \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = cluster(dist)\n",
    "plt.figure()\n",
    "dn = hierarchy.dendrogram(Z, labels=C_labels, leaf_rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Q4c -- Bonus:_ Implement complete linkage clustering. [5 points]\n",
    "_Hint:_ The documentation for the required output format is described here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage. Your plot should be identical to the below scipy plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "Z = hierarchy.linkage(C_values, 'complete', 'cityblock')\n",
    "plt.figure()\n",
    "dn = hierarchy.dendrogram(Z, labels=C_labels, leaf_rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
